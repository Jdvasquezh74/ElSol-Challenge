# ElSol Challenge - Documentaci√≥n T√©cnica Completa

**Proyecto:** ElSol Challenge - Plataforma M√©dica Inteligente  
**Versi√≥n:** 1.0.0  
**Fecha:** Enero 2025  
**Autor:** Equipo de Desarrollo ElSol Challenge  

---

## Tabla de Contenidos

1. [Resumen Ejecutivo](#1-resumen-ejecutivo)
2. [Arquitectura General del Sistema](#2-arquitectura-general-del-sistema)
3. [Servicios Principales](#3-servicios-principales)
   - 3.1 [Servicio de Transcripci√≥n Whisper](#31-servicio-de-transcripci√≥n-whisper)
   - 3.2 [Servicio de Extracci√≥n OpenAI](#32-servicio-de-extracci√≥n-openai)
   - 3.3 [Servicio Vector Store](#33-servicio-vector-store)
   - 3.4 [Servicio Chat RAG](#34-servicio-chat-rag)
   - 3.5 [Servicio OCR y Documentos](#35-servicio-ocr-y-documentos)
   - 3.6 [Servicio Speaker Diarization](#36-servicio-speaker-diarization)
4. [API y Endpoints](#4-api-y-endpoints)
5. [Base de Datos y Schemas](#5-base-de-datos-y-schemas)
6. [Decisiones Arquitect√≥nicas](#6-decisiones-arquitect√≥nicas)
7. [Migraci√≥n a Microservicios](#7-migraci√≥n-a-microservicios)
8. [Despliegue y Operaciones](#8-despliegue-y-operaciones)

---

## 1. Resumen Ejecutivo

ElSol Challenge es una plataforma m√©dica inteligente que combina transcripci√≥n de audio, procesamiento de documentos, almacenamiento vectorial y un sistema de chat RAG para crear un asistente m√©dico completo.

El sistema est√° construido como un **monolito modular** usando Python/FastAPI en el backend y React/TypeScript en el frontend, dise√±ado para evolucionar gradualmente hacia microservicios cuando sea necesario.

### Caracter√≠sticas Principales

- **üé§ Transcripci√≥n de Audio**: Whisper local para privacidad m√©dica
- **ü§ñ Extracci√≥n de Informaci√≥n**: Azure OpenAI para datos m√©dicos estructurados
- **üîç Almacenamiento Vectorial**: ChromaDB para b√∫squeda sem√°ntica
- **üí¨ Chat Inteligente**: Sistema RAG completo
- **üìÑ Procesamiento de Documentos**: OCR y extracci√≥n de PDFs m√©dicos
- **üë• Diferenciaci√≥n de Hablantes**: Clasificaci√≥n promotor vs. paciente

### Stack Tecnol√≥gico

**Backend:**
- Framework: FastAPI (Python)
- Base de Datos: SQLite (dev) / PostgreSQL (prod)
- ORM: SQLAlchemy con Alembic
- Vector DB: ChromaDB
- Embeddings: sentence-transformers
- Transcripci√≥n: OpenAI Whisper (local)
- IA: Azure OpenAI GPT-4
- OCR: Tesseract + PyPDF2

**Frontend:**
- Framework: React 18 + TypeScript
- Styling: Tailwind CSS
- Build Tool: Vite
- HTTP Client: Axios
- State Management: React Hooks

---

## 2. Arquitectura General del Sistema

### 2.1 Arquitectura de Alto Nivel

![Arquitectura Alto Nivel](images/arquitectura-alto-nivel.png)

La arquitectura sigue un patr√≥n de capas bien definidas:

1. **Presentation Layer**: React Frontend + FastAPI
2. **Business Logic Layer**: Servicios especializados
3. **Data Access Layer**: ORM + Vector DB Client
4. **Infrastructure Layer**: Bases de datos y servicios externos

### 2.2 Flujo de Datos Principal

![Flujo de Datos](images/flujo-datos-principal.png)

**Pipeline de Audio:**
1. Audio Upload ‚Üí Whisper Transcription
2. Transcription ‚Üí OpenAI Information Extraction
3. Extraction ‚Üí Vector Store Storage
4. Vector Storage ‚Üí Speaker Diarization

**Pipeline de Documentos:**
1. Document Upload ‚Üí OCR/PDF Processing
2. Text Extraction ‚Üí Medical Metadata Extraction
3. Metadata ‚Üí Vector Store Storage

**Pipeline RAG:**
1. User Query ‚Üí RAG Pipeline
2. Vector Search ‚Üí Context Ranking
3. Context ‚Üí GPT-4 Response Generation

### 2.3 Arquitectura de Servicios

![Arquitectura de Servicios](images/arquitectura-servicios.png)

El sistema implementa una arquitectura modular con servicios especializados:

- **WhisperService**: Transcripci√≥n de audio local
- **OpenAIService**: Extracci√≥n de informaci√≥n y chat
- **VectorStoreService**: Almacenamiento vectorial
- **ChatService**: Sistema RAG completo
- **OCRService**: Procesamiento de documentos
- **SpeakerService**: Diferenciaci√≥n de hablantes

---

## 3. Servicios Principales

### 3.1 Servicio de Transcripci√≥n Whisper

#### Descripci√≥n General
El servicio de transcripci√≥n Whisper es el componente central para convertir archivos de audio en texto utilizando el modelo Whisper de OpenAI ejecutado localmente. Este servicio no requiere conexi√≥n a internet ni API keys, proporcionando privacidad y control total sobre los datos m√©dicos.

#### Clase Principal: `LocalWhisperService`

**Responsabilidades:**
- Carga lazy del modelo Whisper
- Validaci√≥n de archivos de audio
- Transcripci√≥n con par√°metros configurables
- C√°lculo de m√©tricas de confianza
- Detecci√≥n autom√°tica de idioma

**Atributos principales:**
```python
- model_name: str        # Modelo Whisper a usar (tiny, base, small, medium, large)
- device: str           # Dispositivo de ejecuci√≥n (cpu/cuda)
- model: whisper.Model  # Instancia del modelo cargado
- timeout: int          # Timeout para transcripci√≥n
```

#### Integraci√≥n con Core y Database

**Configuraci√≥n (`app.core.config`):**
```python
WHISPER_MODEL: str = "base"           # Modelo a usar
WHISPER_DEVICE: str = "cpu"           # cpu o cuda
TRANSCRIPTION_TIMEOUT: int = 300      # 5 minutos
UPLOAD_MAX_SIZE: int = 26_214_400     # 25MB
UPLOAD_ALLOWED_EXTENSIONS: List[str]  # [wav, mp3]
```

**Database Models (`app.database.models`):**
Integraci√≥n con `AudioTranscription`:
```python
raw_transcription: str
confidence_score: str
language_detected: str
audio_duration_seconds: int
processing_time_seconds: int
whisper_model_used: str
```

#### Caracter√≠sticas T√©cnicas

**Modelos Whisper Disponibles:**
- **tiny**: ~39 MB, ~32x speed, precisi√≥n b√°sica
- **base**: ~74 MB, ~16x speed, buena precisi√≥n
- **small**: ~244 MB, ~6x speed, muy buena precisi√≥n
- **medium**: ~769 MB, ~2x speed, excelente precisi√≥n
- **large**: ~1550 MB, ~1x speed, m√°xima precisi√≥n

**Validaciones Implementadas:**
1. Archivo existente y tama√±o v√°lido
2. Extensi√≥n permitida (wav, mp3)
3. Magic numbers (RIFF/WAVE, ID3/MP3)
4. L√≠mites de tama√±o (25MB m√°ximo)

#### API Endpoints Asociados

- **`POST /upload-audio`**: Carga de archivos con procesamiento as√≠ncrono
- **`GET /transcriptions/{id}`**: Consulta de estado y resultados

---

### 3.2 Servicio de Extracci√≥n OpenAI

#### Descripci√≥n General
El servicio OpenAI es responsable de extraer informaci√≥n estructurada y no estructurada de las transcripciones de audio utilizando modelos de Azure OpenAI. Este servicio transforma texto crudo en datos m√©dicos organizados y √∫tiles para an√°lisis posterior.

#### Clase Principal: `OpenAIService`

**Responsabilidades:**
- Comunicaci√≥n con Azure OpenAI API
- Extracci√≥n de informaci√≥n estructurada (nombres, edades, diagn√≥sticos)
- An√°lisis de datos no estructurados (s√≠ntomas, emociones, contexto)
- Generaci√≥n de respuestas para el chatbot
- Validaci√≥n y limpieza de datos extra√≠dos

#### Prompts Especializados

**Extracci√≥n Estructurada:**
```python
STRUCTURED_EXTRACTION_PROMPT = """
Eres un asistente m√©dico especializado en extraer informaci√≥n espec√≠fica 
de conversaciones m√©dicas. Analiza esta transcripci√≥n y extrae √öNICAMENTE 
la informaci√≥n que est√© expl√≠citamente mencionada.

CAMPOS A EXTRAER:
- nombre: Nombre del paciente
- edad: Edad mencionada (0-150)
- fecha: Fecha de la conversaci√≥n
- diagnostico: Diagn√≥stico m√©dico
- medico: Nombre del m√©dico/profesional
- medicamentos: Lista de medicamentos mencionados
- telefono: N√∫mero de tel√©fono
- email: Correo electr√≥nico
"""
```

**An√°lisis No Estructurado:**
```python
UNSTRUCTURED_ANALYSIS_PROMPT = """
Analiza esta conversaci√≥n m√©dica y extrae informaci√≥n contextual y emocional.
Enf√≥cate en aspectos que no son datos espec√≠ficos pero son importantes 
para el seguimiento m√©dico.

CAMPOS A ANALIZAR:
- sintomas: Lista de s√≠ntomas mencionados
- contexto: Contexto general de la conversaci√≥n
- observaciones: Observaciones adicionales
- emociones: Estados emocionales detectados
- urgencia: Nivel de urgencia (baja/media/alta)
- recomendaciones: Recomendaciones dadas
"""
```

#### Manejo de Rate Limiting
```python
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10),
    retry=retry_if_exception_type(RateLimitError)
)
async def _call_openai_api():
    # L√≥gica de llamada con reintentos autom√°ticos
```

---

### 3.3 Servicio Vector Store

#### Descripci√≥n General
El VectorStoreService implementa el almacenamiento vectorial usando ChromaDB para convertir transcripciones m√©dicas en embeddings sem√°nticamente ricos, permitiendo b√∫squedas avanzadas y el sistema RAG.

#### Clase Principal: `VectorStoreService`

**Responsabilidades:**
- Inicializaci√≥n y gesti√≥n de ChromaDB
- Generaci√≥n de embeddings con sentence-transformers
- Almacenamiento de transcripciones con metadata rica
- B√∫squeda sem√°ntica avanzada
- B√∫squedas especializadas (por paciente, por condici√≥n)

#### Arquitectura de Almacenamiento

**Estructura de Embeddings:**
```python
{
    "id": "conv_12345_abc123",          # ID √∫nico del vector
    "embedding": [0.1, 0.2, ...],      # Vector de 384 dimensiones
    "document": "texto_preparado",      # Texto combinado para embedding
    "metadata": {                       # Metadata rica
        "conversation_id": "12345",
        "patient_name": "Juan P√©rez",
        "diagnosis": "hipertensi√≥n",
        "symptoms": "dolor de cabeza, mareos",
        "conversation_date": "2024-01-15",
        "created_at": "2024-01-15T10:30:00Z",
        "document_type": "transcription"
    }
}
```

#### Funcionalidades de B√∫squeda

1. **B√∫squeda Sem√°ntica General**: Similarity search con filtros
2. **B√∫squeda por Paciente**: Fuzzy matching para nombres latinos
3. **B√∫squeda por Condici√≥n**: Filtrado por diagn√≥sticos m√©dicos

---

### 3.4 Servicio Chat RAG

#### Descripci√≥n General
El ChatService implementa un sistema completo RAG (Retrieval-Augmented Generation) especializado en consultas m√©dicas. Combina an√°lisis de intenci√≥n, b√∫squeda vectorial sem√°ntica y generaci√≥n de respuestas contextuales.

#### Pipeline RAG Completo

![Pipeline RAG](images/pipeline-rag.png)

1. **An√°lisis de Query**: Normalizaci√≥n y detecci√≥n de intenci√≥n
2. **Extracci√≥n de Entidades**: Pacientes, condiciones, s√≠ntomas
3. **B√∫squeda Vectorial**: Recuperaci√≥n de contexto relevante
4. **Ranking de Contexto**: Ordenamiento por relevancia
5. **Generaci√≥n**: Respuesta con GPT-4 y fuentes

#### Tipos de Intenciones

```python
class ChatIntent(str, Enum):
    PATIENT_INFO = "patient_info"        # "¬øQu√© enfermedad tiene X?"
    CONDITION_LIST = "condition_list"    # "Listame pacientes con diabetes"
    SYMPTOM_SEARCH = "symptom_search"    # "¬øQui√©n tiene dolor de cabeza?"
    MEDICATION_INFO = "medication_info"  # "¬øQu√© medicamentos toma X?"
    TEMPORAL_QUERY = "temporal_query"    # "¬øQu√© pas√≥ la semana pasada?"
    GENERAL_QUERY = "general_query"      # Consultas generales
```

#### Estrategias de B√∫squeda por Intenci√≥n

```python
if intent == ChatIntent.PATIENT_INFO:
    # B√∫squeda espec√≠fica por paciente
    results = await vector_service.search_by_patient(patient_name)
elif intent == ChatIntent.CONDITION_LIST:
    # B√∫squeda por condici√≥n m√©dica
    results = await vector_service.search_by_condition(condition)
else:
    # B√∫squeda sem√°ntica general
    results = await vector_service.semantic_search(query)
```

---

### 3.5 Servicio OCR y Documentos

#### Descripci√≥n General
El OCRService maneja el procesamiento completo de documentos m√©dicos (PDFs e im√°genes) extrayendo texto mediante PyPDF2 y Tesseract OCR, seguido de extracci√≥n de metadata m√©dica usando IA.

#### Clase Principal: `OCRService`

**Responsabilidades:**
- Detecci√≥n autom√°tica de tipo de archivo (PDF vs imagen)
- Extracci√≥n de texto de PDFs usando PyPDF2
- OCR de im√°genes usando Tesseract
- Limpieza y normalizaci√≥n de texto extra√≠do
- Extracci√≥n de metadata m√©dica usando OpenAI
- Validaci√≥n de archivos y configuraci√≥n de calidad

#### Pipeline de Procesamiento

![Pipeline Documentos](images/pipeline-documentos.png)

**Flujo:**
1. Upload PDF/Imagen ‚Üí Detecci√≥n de tipo
2. PDF ‚Üí PyPDF2 Extraction | Imagen ‚Üí Tesseract OCR
3. Texto Extra√≠do ‚Üí Limpieza
4. OpenAI Service ‚Üí Extracci√≥n Metadata M√©dica
5. Document Model DB + Vector Store Service

#### Detecci√≥n de Tipo de Archivo

```python
def detect_file_type(self, file_path: str) -> str:
    # M√©todos de detecci√≥n:
    # 1. MIME type analysis
    # 2. File extension validation
    # 3. Magic number verification
    
    if mime_type == "application/pdf":
        return "pdf"
    elif mime_type.startswith("image/"):
        return "image"
```

#### Configuraci√≥n OCR

```python
# Configuraci√≥n Tesseract:
OCR_LANGUAGE: str = "spa"            # Espa√±ol
OCR_MIN_CONFIDENCE: int = 60         # Confianza m√≠nima
PDF_MAX_PAGES: int = 50              # L√≠mite de p√°ginas
DOCUMENT_MAX_SIZE_MB: int = 10       # Tama√±o m√°ximo
```

---

### 3.6 Servicio Speaker Diarization

#### Descripci√≥n General
El SpeakerService implementa diarizaci√≥n de hablantes especializada en conversaciones m√©dicas, identificando y separando autom√°ticamente la participaci√≥n del promotor de salud y el paciente.

#### Enfoque H√≠brido

**M√©todo Avanzado (Audio + Texto):**
```python
if whisper_segments and librosa_available:
    # An√°lisis de caracter√≠sticas de audio + texto
    segments = _diarize_with_audio_and_text()
else:
    # M√©todo b√°sico: solo an√°lisis de texto
    segments = _diarize_text_only()
```

#### Caracter√≠sticas de Audio Extra√≠das

1. **Pitch Analysis**: Frecuencia fundamental (f0)
2. **Energy Analysis**: RMS energy
3. **Spectral Analysis**: Centroide espectral
4. **Speech Rate**: Zero crossing rate
5. **Tonal Variability**: Rango de pitch

#### Patrones de Clasificaci√≥n

**Promotor de Salud:**
```python
_promotor_patterns = [
    r"buenos d√≠as|buenas tardes|hola",
    r"¬øc√≥mo se siente|¬øc√≥mo est√°|¬øqu√© le pasa",
    r"vamos a revisar|le voy a|necesito que",
    r"voy a recetarle|le recomiendo|debe tomar"
]
```

**Paciente:**
```python
_paciente_patterns = [
    r"me duele|me siento|tengo dolor",
    r"desde hace|hace como|hace unos",
    r"s√≠ doctor|no doctor|gracias doctor",
    r"mi familia|mi trabajo|en casa"
]
```

#### Estad√≠sticas Generadas

```python
class SpeakerStats:
    total_speakers: int                    # Hablantes √∫nicos detectados
    promotor_time: float                   # Tiempo total del promotor
    paciente_time: float                   # Tiempo total del paciente
    speaker_changes: int                   # N√∫mero de cambios de hablante
    average_segment_length: float          # Duraci√≥n promedio de segmentos
```

---

## 4. API y Endpoints

### 4.1 Estructura de Rutas

```python
# Configuraci√≥n de Routers
app.include_router(health.router, tags=["Health Check"])
app.include_router(upload.router, prefix="/api/v1", tags=["Audio Transcription"])
app.include_router(vector.router, prefix="/api/v1", tags=["Vector Store"])
app.include_router(chat.router, prefix="/api/v1", tags=["Chat RAG"])
app.include_router(documents.router, prefix="/api/v1", tags=["Document Processing"])
```

### 4.2 Endpoints Principales

#### Audio Transcription

**`POST /api/v1/upload-audio`**
- **Descripci√≥n**: Subir archivo de audio para transcripci√≥n autom√°tica
- **Content-Type**: `multipart/form-data`
- **Validaciones**: Tama√±o m√°ximo 25MB, extensiones wav/mp3
- **Response**: `AudioUploadResponse` con ID de transcripci√≥n

**`GET /api/v1/transcriptions/{transcription_id}`**
- **Descripci√≥n**: Obtener resultados de transcripci√≥n por ID
- **Response**: `TranscriptionResponse` con texto, datos estructurados y no estructurados

#### Chat RAG

**`POST /api/v1/chat`**
- **Descripci√≥n**: Endpoint principal para consultas m√©dicas con sistema RAG
- **Request**: `ChatQuery` con query, max_results, filtros
- **Response**: `ChatResponse` con respuesta, fuentes, confianza

**Tipos de consultas soportadas:**
- `patient_info`: "¬øQu√© enfermedad tiene X?"
- `condition_list`: "Listame pacientes con diabetes"
- `symptom_search`: "¬øQui√©n tiene dolor de cabeza?"
- `medication_info`: "¬øQu√© medicamentos toma X?"
- `temporal_query`: "¬øQu√© pas√≥ ayer?"

#### Vector Store

**`GET /api/v1/vector-store/status`**
- **Descripci√≥n**: Estado actual del vector store y estad√≠sticas
- **Response**: `VectorStoreStatus` con total de documentos, modelo de embeddings

**`GET /api/v1/vector-store/conversations`**
- **Descripci√≥n**: Lista de conversaciones almacenadas
- **Query Params**: `limit` (1-100, default 20)
- **Response**: Lista de `StoredConversation`

#### Document Processing

**`POST /api/v1/documents/upload`**
- **Descripci√≥n**: Subir y procesar documentos m√©dicos
- **Content-Type**: `multipart/form-data`
- **Formatos**: PDF, JPG, PNG, TIFF hasta 10MB
- **Response**: `DocumentResponse` con ID y estado

### 4.3 Pipeline de Procesamiento API

![Pipeline API](images/pipeline-api.png)

**Flujo de Upload de Audio:**
1. Usuario ‚Üí Frontend ‚Üí POST /upload-audio
2. API ‚Üí Database (crear registro) ‚Üí Background Tasks
3. Background: Whisper ‚Üí OpenAI ‚Üí Vector Store ‚Üí Speaker Diarization
4. Usuario consulta estado ‚Üí GET /transcriptions/{id}

---

## 5. Base de Datos y Schemas

### 5.1 Arquitectura de Base de Datos

**Configuraci√≥n:**
- **Desarrollo**: SQLite (`./conversations.db`)
- **Producci√≥n**: PostgreSQL
- **ORM**: SQLAlchemy con Alembic para migraciones

### 5.2 Modelos Principales

#### AudioTranscription (Tabla Principal)

```python
class AudioTranscription(Base):
    __tablename__ = "audio_transcriptions"
    
    # Clave primaria
    id = Column(String, primary_key=True)
    
    # Informaci√≥n del archivo
    filename = Column(String(255), nullable=False)
    file_size = Column(Integer, nullable=False)
    file_type = Column(String(50), nullable=False)
    
    # Estado de procesamiento
    status = Column(Enum(TranscriptionStatus), default=TranscriptionStatus.PENDING)
    
    # Timestamps
    created_at = Column(DateTime, default=datetime.utcnow)
    processed_at = Column(DateTime, nullable=True)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    # Resultados de transcripci√≥n
    raw_transcription = Column(Text, nullable=True)
    confidence_score = Column(String(10), nullable=True)
    
    # Informaci√≥n estructurada extra√≠da (JSON)
    structured_data = Column(JSON, nullable=True)
    
    # Informaci√≥n no estructurada (JSON)
    unstructured_data = Column(JSON, nullable=True)
    
    # Integraci√≥n Vector Store
    vector_stored = Column(String(50), default="false")
    vector_id = Column(String(100), nullable=True)
    
    # Speaker Diarization
    speaker_segments = Column(Text, nullable=True)  # JSON array
    speaker_stats = Column(Text, nullable=True)     # JSON object
```

#### Document (Procesamiento de Documentos)

```python
class Document(Base):
    __tablename__ = "documents"
    
    # Identificaci√≥n
    id = Column(String(50), primary_key=True)
    filename = Column(String(255), nullable=False)
    file_type = Column(String(10), nullable=False)  # 'pdf', 'image'
    file_size_bytes = Column(Integer, nullable=False)
    
    # Resultados OCR/extracci√≥n
    extracted_text = Column(Text, nullable=True)
    ocr_confidence = Column(Float, nullable=True)
    page_count = Column(Integer, nullable=True)
    
    # Metadata m√©dica extra√≠da por IA
    patient_name = Column(String(100), nullable=True)
    document_date = Column(String(20), nullable=True)
    document_type = Column(String(50), nullable=True)
    medical_conditions = Column(Text, nullable=True)  # JSON array
    medications = Column(Text, nullable=True)         # JSON array
    
    # Integraci√≥n vector store
    vector_stored = Column(String(10), default="false")
    vector_id = Column(String(100), nullable=True)
    
    # Relaci√≥n con conversaciones
    conversation_id = Column(String(50), ForeignKey("audio_transcriptions.id"))
```

### 5.3 Estructura de Datos JSON

#### Structured Data (AudioTranscription)
```json
{
    "nombre": "Juan P√©rez",
    "edad": 45,
    "fecha": "2024-01-15",
    "diagnostico": "hipertensi√≥n arterial",
    "medico": "Dr. Garc√≠a",
    "medicamentos": ["losartan", "amlodipino"],
    "telefono": "+1234567890",
    "email": "juan.perez@email.com"
}
```

#### Unstructured Data (AudioTranscription)
```json
{
    "sintomas": ["dolor de cabeza", "mareos", "fatiga"],
    "contexto": "consulta de seguimiento para hipertensi√≥n",
    "observaciones": "paciente muestra buena adherencia al tratamiento",
    "emociones": ["preocupaci√≥n", "alivio"],
    "urgencia": "media",
    "recomendaciones": ["continuar medicaci√≥n", "dieta baja en sodio"],
    "preguntas": ["¬øCu√°ndo debo regresar?", "¬øPuedo hacer ejercicio?"],
    "respuestas": ["seguimiento en 3 meses", "ejercicio ligero recomendado"]
}
```

#### Speaker Segments (JSON Text)
```json
[
    {
        "speaker": "promotor",
        "text": "Buenos d√≠as, ¬øc√≥mo se siente hoy?",
        "start_time": 0.0,
        "end_time": 3.2,
        "confidence": 0.89,
        "word_count": 6
    },
    {
        "speaker": "paciente",
        "text": "Me duele mucho la cabeza desde ayer",
        "start_time": 3.5,
        "end_time": 7.1,
        "confidence": 0.82,
        "word_count": 7
    }
]
```

### 5.4 Diagrama Entidad-Relaci√≥n

![Diagrama ER](images/diagrama-er.png)

**Relaciones:**
- `AudioTranscription` 1:N `Document` (conversation_id)
- `AudioTranscription` 1:1 `ConversationMetadata` (transcription_id)
- Integraci√≥n con ChromaDB v√≠a `vector_id`

---

## 6. Decisiones Arquitect√≥nicas

### 6.1 Monolito Modular vs Microservicios

**Decisi√≥n**: Comenzar con monolito modular

**Razones:**
‚úÖ **Ventajas del Monolito:**
- Simplicidad de desarrollo y despliegue
- Debugging simplificado con stack traces completos
- Transacciones ACID garantizadas
- Menor latencia (comunicaci√≥n in-process)
- Setup inicial r√°pido sin overhead de networking

‚ùå **Desventajas conocidas:**
- Escalabilidad limitada por el componente m√°s lento
- Deployment monol√≠tico (todo o nada)
- Potencial coupling entre m√≥dulos sin disciplina

**Estrategia de mitigaci√≥n:**
- Arquitectura modular estricta con interfaces bien definidas
- Dependency injection para reducir coupling
- Preparaci√≥n para extraer servicios independientes

### 6.2 Stack Tecnol√≥gico: Python + FastAPI

**Decisi√≥n**: Python con FastAPI como framework principal

**Razones para FastAPI:**
‚úÖ **Python ecosystem para ML/AI:**
- Whisper (OpenAI) tiene implementaci√≥n nativa en Python
- sentence-transformers para embeddings
- Amplio ecosistema de librer√≠as m√©dicas

‚úÖ **FastAPI caracter√≠sticas:**
- Performance comparable a Node.js
- Type hints nativos
- Documentaci√≥n autom√°tica (OpenAPI/Swagger)
- Async/await nativo
- Validaci√≥n autom√°tica con Pydantic

### 6.3 Base de Datos: SQLite + PostgreSQL

**Estrategia h√≠brida:**
```python
if environment == "development":
    DATABASE_URL = "sqlite:///./conversations.db"
else:
    DATABASE_URL = "postgresql://user:pass@host:port/db"
```

**Razones SQLite (Desarrollo):**
- ‚úÖ Zero-configuration
- ‚úÖ Ideal para desarrollo local
- ‚úÖ Transacciones ACID completas

**Razones PostgreSQL (Producci√≥n):**
- ‚úÖ Escalabilidad horizontal y vertical
- ‚úÖ Concurrencia avanzada (MVCC)
- ‚úÖ Tipos de datos avanzados (JSON, arrays)

### 6.4 Vector Database: ChromaDB

**Decisi√≥n**: ChromaDB para almacenamiento vectorial

**Razones:**
- ‚úÖ **Simplicidad**: Instalaci√≥n con pip, configuraci√≥n m√≠nima
- ‚úÖ **Local-first**: No dependencias externas
- ‚úÖ **Persistencia**: Datos almacenados localmente
- ‚úÖ **Python nativo**: Integraci√≥n perfecta
- ‚úÖ **Embeddings integrados**: Soporte directo para sentence-transformers

**Consideraciones futuras:**
- Migraci√≥n a Qdrant o Weaviate para escalabilidad
- pgvector para simplificar stack (un solo DB)

### 6.5 Transcripci√≥n: Whisper Local

**Decisi√≥n**: OpenAI Whisper ejecutado localmente

**Razones Whisper Local:**
- ‚úÖ **Privacidad**: Datos m√©dicos no salen del servidor
- ‚úÖ **Costo predecible**: Sin costos por uso
- ‚úÖ **Latencia controlada**: Sin dependencia de internet
- ‚úÖ **Calidad**: Estado del arte en transcripci√≥n
- ‚ùå **Recursos**: Requiere GPU para modelos grandes

### 6.6 Extracci√≥n de Informaci√≥n: Azure OpenAI

**Razones Azure vs OpenAI directo:**
- ‚úÖ **Compliance**: Mejor para datos m√©dicos
- ‚úÖ **SLA**: Garant√≠as empresariales
- ‚úÖ **Security**: VNet integration, private endpoints

---

## 7. Migraci√≥n a Microservicios

### 7.1 Servicios Candidatos

![Microservicios Target](images/microservicios-target.png)

**1. Transcription Service**
```python
# Responsabilidades:
- Audio file upload/validation
- Whisper transcription
- Speaker diarization
- Audio metadata extraction

# API Surface:
POST /transcriptions
GET /transcriptions/{id}
GET /transcriptions/{id}/speakers
```

**2. Extraction Service**
```python
# Responsabilidades:
- Text analysis con OpenAI
- Structured data extraction
- Medical entity recognition
- Data validation

# API Surface:
POST /extractions
GET /extractions/{id}
POST /extractions/batch
```

**3. Knowledge Service**
```python
# Responsabilidades:
- Vector storage (ChromaDB)
- Semantic search
- Document processing
- Knowledge graph management

# API Surface:
POST /knowledge/store
GET /knowledge/search
POST /knowledge/documents
```

**4. Chat Service**
```python
# Responsabilidades:
- RAG pipeline
- Intent classification
- Response generation
- Chat history

# API Surface:
POST /chat/query
GET /chat/history
POST /chat/feedback
```

### 7.2 Estrategia de Migraci√≥n

#### Fase 1: Strangler Fig Pattern

![Strangler Fig](images/strangler-fig.png)

**Objetivo**: Extraer servicios gradualmente sin interrumpir el monolito

**Implementaci√≥n:**
1. **Feature flags** para dirigir tr√°fico
2. **Dual write** para sincronizar datos
3. **Shadow mode** para validar servicios nuevos

#### Fase 2: Database per Service

**Problema actual**: Base de datos compartida

**Soluci√≥n**: Database decomposition pattern

![Database Decomposition](images/database-decomposition.png)

**Estrategia:**
1. Separar datos por bounded context
2. Event sourcing para sincronizaci√≥n
3. Change Data Capture (CDC) para transici√≥n

#### Fase 3: Service Mesh + API Gateway

**Infraestructura objetivo:**

![Service Mesh](images/service-mesh.png)

**Componentes:**
- **API Gateway**: Kong/Istio Gateway
- **Service Mesh**: Istio/Linkerd
- **Message Queue**: Redis/RabbitMQ
- **Monitoring**: Prometheus + Grafana

### 7.3 Service Communication Patterns

**Current (Monolith):**
```python
# In-process communication
async def upload_audio():
    transcription = await whisper_service.transcribe(file)
    extracted = await openai_service.extract(transcription)
    vector_id = await vector_service.store(extracted)
    return result
```

**Future (Microservices):**
```python
# Event-driven communication
async def upload_audio():
    event_bus.publish("audio.uploaded", audio_data)
    return {"status": "processing", "id": audio_id}

@event_handler("audio.uploaded")
async def handle_audio_uploaded(audio_data):
    transcription = await transcribe(audio_data)
    event_bus.publish("audio.transcribed", transcription)
```

### 7.4 Data Consistency Strategy

**Current: ACID Transactions**
```python
@db_transaction
async def process_audio(audio_file):
    # Atomicidad garantizada
    transcription = create_transcription(audio_file)
    structured_data = extract_information(transcription.text)
    vector_id = store_in_vector_db(transcription, structured_data)
    transcription.vector_id = vector_id
    commit()  # Todo o nada
```

**Future: Eventual Consistency + Saga Pattern**
```python
class AudioProcessingSaga:
    async def execute(self, audio_file):
        try:
            # Step 1: Create transcription
            transcription_id = await transcription_service.create(audio_file)
            
            # Step 2: Extract information
            extraction_id = await extraction_service.process(transcription_id)
            
            # Step 3: Store in vector DB
            vector_id = await knowledge_service.store(extraction_id)
            
            # Success: Mark as completed
            await transcription_service.mark_completed(transcription_id, vector_id)
            
        except Exception as e:
            # Compensation: Rollback steps
            await self.compensate(transcription_id, extraction_id)
```

### 7.5 Timeline de Migraci√≥n

**Q1 2024: Preparaci√≥n**
- [ ] Refactoring para interfaces claras
- [ ] Implementar event sourcing patterns
- [ ] Setup de infrastructure (Kubernetes, monitoring)
- [ ] Feature flags y A/B testing framework

**Q2 2024: Primer Servicio**
- [ ] Extraer Transcription Service
- [ ] Database per service pattern
- [ ] Service-to-service communication
- [ ] Comprehensive testing

**Q3 2024: Segundo y Tercer Servicio**
- [ ] Extraer Knowledge Service
- [ ] Extraer Chat Service
- [ ] API Gateway implementation
- [ ] Service mesh (Istio/Linkerd)

**Q4 2024: Completar Migraci√≥n**
- [ ] Extraer servicios restantes
- [ ] Performance optimization
- [ ] Security hardening
- [ ] Documentation y training

---

## 8. Despliegue y Operaciones

### 8.1 Desarrollo Local

```bash
# Backend
cd backend
pip install -r requirements.txt
uvicorn app.main:app --reload

# Frontend  
cd frontend
npm install
npm run dev
```

### 8.2 Producci√≥n

**Containerizaci√≥n**:
```dockerfile
# Dockerfile para backend
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Orquestaci√≥n**:
```yaml
# docker-compose.yml
version: '3.8'
services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/elsol
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
    depends_on:
      - db
      - chroma
  
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    depends_on:
      - backend
  
  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=elsol
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
  
  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    ports:
      - "8001:8000"
    volumes:
      - chroma_data:/chroma/chroma
```

### 8.3 Monitoreo y Observabilidad

**M√©tricas Clave**:
- **Performance**: Latencia p95 < 500ms, Throughput > 1000 req/min
- **Reliability**: Uptime 99.9%, MTTR < 30 min
- **Business**: Accuracy > 90%, User satisfaction

**Stack de Monitoreo**:
- **Metrics**: Prometheus + Grafana
- **Logging**: ELK Stack (Elasticsearch, Logstash, Kibana)
- **Tracing**: Jaeger para distributed tracing
- **Alerting**: AlertManager + PagerDuty

### 8.4 Seguridad y Compliance

**Privacidad M√©dica**:
- **Datos Locales**: Whisper ejecuta sin enviar datos externos
- **Encriptaci√≥n**: TLS en tr√°nsito, AES-256 en reposo
- **Audit Logs**: Trazabilidad de acceso a informaci√≥n
- **HIPAA Ready**: Preparado para compliance m√©dico

**Arquitectura de Seguridad**:
- **Input Validation**: Validaci√≥n en todas las capas
- **Authentication**: JWT tokens con refresh
- **Authorization**: RBAC (Role-Based Access Control)
- **Rate Limiting**: Por usuario y por endpoint

---

## Conclusi√≥n

ElSol Challenge representa una soluci√≥n m√©dica moderna que combina las mejores pr√°cticas de desarrollo de software con tecnolog√≠as de inteligencia artificial de vanguardia. La arquitectura monol√≠tica modular permite desarrollo r√°pido mientras prepara el terreno para una evoluci√≥n gradual hacia microservicios cuando el negocio lo requiera.

### Logros T√©cnicos

1. **Privacidad M√©dica**: Whisper local garantiza que datos sensibles no salen del servidor
2. **Escalabilidad Preparada**: Arquitectura modular lista para microservicios
3. **IA Especializada**: Prompts m√©dicos optimizados para extracci√≥n precisa
4. **B√∫squeda Inteligente**: Sistema RAG completo para consultas naturales
5. **Multi-modal**: Audio, documentos y chat en una plataforma unificada

### Roadmap Futuro

**Corto Plazo (Q1 2024)**:
- Optimizaci√≥n de performance y tests completos
- Security hardening y documentaci√≥n API
- Mobile app integration

**Medio Plazo (Q2-Q3 2024)**:
- Real-time transcription con WebSockets
- Advanced analytics dashboard
- Multi-language support

**Largo Plazo (Q4 2024+)**:
- Migraci√≥n gradual a microservicios
- Advanced ML models especializados en medicina
- Integration con sistemas hospitalarios (HL7 FHIR)
- Multi-tenancy y features enterprise

La documentaci√≥n completa facilita el onboarding de nuevos desarrolladores, la comprensi√≥n del sistema por parte de stakeholders, y proporciona una gu√≠a clara para la evoluci√≥n futura del proyecto.

---

**Fecha de actualizaci√≥n**: Enero 2025  
**Versi√≥n del documento**: 1.0.0  
**Pr√≥xima revisi√≥n**: Marzo 2025
